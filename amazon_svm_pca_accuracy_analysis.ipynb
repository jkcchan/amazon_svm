{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np \n",
    "import pickle\n",
    "\n",
    "import time\n",
    "n_components_iteration = [2, 5, 25, 48, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pca(n_components, X_train):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_and_normalize(data, clf):\n",
    "    return normalize(clf.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svm(data, labels):\n",
    "    clf = svm.LinearSVR(random_state=0, tol=1e-5)\n",
    "    clf.fit(data, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svc(data, labels):\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    clf.fit(data, labels)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svm(clf, test_data):\n",
    "    y_pred = clf.predict(test_data)\n",
    "    y_pred_bin = [0 if i < 0.5 else 1 for i in y_pred]\n",
    "    return y_pred_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all(svc=False):\n",
    "    with open('./pca_data/pca_classifiers'+('_svc' if svc else '')+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(pca_classifiers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('./pca_data/svm_classifiers'+('_svc' if svc else '')+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(svm_classifiers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('./pca_data/X_train_transformed_normalized'+('_svc' if svc else '')+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(X_train_transformed_normalized, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('./pca_data/X_test_transformed_normalized'+('_svc' if svc else '')+'.pickle', 'wb') as handle:\n",
    "        pickle.dump(X_test_transformed_normalized, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('./data/X_train.npy')\n",
    "X_test = np.load('./data/X_test.npy')\n",
    "with open(\"train_labels.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_labels = pickle.load(fp)\n",
    "with open(\"test_labels.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_labels = pickle.load(fp)\n",
    "X_train, X_cv, train_labels, cv_labels = train_test_split(X_train, train_labels, train_size=50000)\n",
    "X_test, X_cv, test_labels, cv_labels = train_test_split(X_test, test_labels, train_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "PCA fit time for 2 components: 0.23015260696411133\n",
      "Transform and Normalization time for 2 components: 0.01818251609802246\n",
      "SVM time for 2 components: 129.164320230484\n",
      "Save time for 2 components: 0.00018095970153808594\n",
      "Test time for 2 components: 13.841394186019897\n",
      "--- Accuracy for 2 components: 0.5193\n",
      "time for 2 components: 143.26092839241028\n",
      "=============\n",
      "5\n",
      "PCA fit time for 5 components: 0.23808932304382324\n",
      "Transform and Normalization time for 5 components: 0.01944112777709961\n",
      "SVM time for 5 components: 120.08865857124329\n",
      "Save time for 5 components: 0.000179290771484375\n",
      "Test time for 5 components: 15.445564985275269\n",
      "--- Accuracy for 5 components: 0.5287\n",
      "time for 5 components: 135.79828524589539\n",
      "=============\n",
      "25\n",
      "PCA fit time for 25 components: 0.3604600429534912\n",
      "Transform and Normalization time for 25 components: 0.028342485427856445\n",
      "SVM time for 25 components: 233.298485994339\n",
      "Save time for 25 components: 0.00018024444580078125\n",
      "Test time for 25 components: 28.547765731811523\n",
      "--- Accuracy for 25 components: 0.5219\n",
      "time for 25 components: 262.2416627407074\n",
      "=============\n",
      "48\n",
      "PCA fit time for 48 components: 0.5484561920166016\n",
      "Transform and Normalization time for 48 components: 0.03916025161743164\n",
      "SVM time for 48 components: 429.59760999679565\n",
      "Save time for 48 components: 0.00018739700317382812\n",
      "Test time for 48 components: 46.932475090026855\n",
      "--- Accuracy for 48 components: 0.5202\n",
      "time for 48 components: 477.12438201904297\n",
      "=============\n",
      "50\n",
      "PCA fit time for 50 components: 0.6137485504150391\n",
      "Transform and Normalization time for 50 components: 0.07556605339050293\n",
      "SVM time for 50 components: 467.10688829421997\n",
      "Save time for 50 components: 0.00033354759216308594\n",
      "Test time for 50 components: 49.24091458320618\n",
      "--- Accuracy for 50 components: 0.5269\n",
      "time for 50 components: 517.0443201065063\n",
      "=============\n",
      "75\n",
      "PCA fit time for 75 components: 1.1682929992675781\n",
      "Transform and Normalization time for 75 components: 0.10211610794067383\n",
      "SVM time for 75 components: 732.4662165641785\n",
      "Save time for 75 components: 0.0001926422119140625\n",
      "Test time for 75 components: 71.31354236602783\n",
      "--- Accuracy for 75 components: 0.5274\n",
      "time for 75 components: 805.056910276413\n",
      "=============\n",
      "100\n",
      "PCA fit time for 100 components: 0.31064367294311523\n",
      "Transform and Normalization time for 100 components: 0.14724206924438477\n",
      "SVM time for 100 components: 919.9006972312927\n",
      "Save time for 100 components: 0.0001766681671142578\n",
      "Test time for 100 components: 92.63358449935913\n",
      "--- Accuracy for 100 components: 0.5219\n",
      "time for 100 components: 1012.9989500045776\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "pca_classifiers = {}\n",
    "svm_classifiers = {}\n",
    "X_train_transformed_normalized = {}\n",
    "X_test_transformed_normalized = {}\n",
    "for i in n_components_iteration:\n",
    "    start = time.time()\n",
    "    print(i)\n",
    "    \n",
    "    pca_clf = build_pca(i, X_train)\n",
    "    pca_time = time.time()\n",
    "    print(\"PCA fit time for \"+str(i)+\" components: \"+str(pca_time-start))\n",
    "    \n",
    "    X_train_trans_norm = transform_and_normalize(X_train, pca_clf)\n",
    "    X_test_trans_norm = transform_and_normalize(X_test, pca_clf)\n",
    "    trans_norm_time = time.time()\n",
    "    print(\"Transform and Normalization time for \"+str(i)+\" components: \"+str(trans_norm_time-pca_time))\n",
    "\n",
    "    \n",
    "    svm_clf = build_svc(X_train_trans_norm, train_labels)\n",
    "    svm_time = time.time()\n",
    "    print(\"SVM time for \"+str(i)+\" components: \"+str(svm_time-trans_norm_time))\n",
    "\n",
    "    \n",
    "    X_train_transformed_normalized[str(i)] = X_train_trans_norm\n",
    "    X_test_transformed_normalized[str(i)] = X_test_trans_norm\n",
    "    pca_classifiers[str(i)] = pca_clf\n",
    "    svm_classifiers[str(i)] = svm_clf\n",
    "    save_time = time.time()\n",
    "    print(\"Save time for \"+str(i)+\" components: \"+str(save_time-svm_time))\n",
    "\n",
    "    \n",
    "    y_pred_bin = test_svm(svm_clf, X_test_trans_norm)\n",
    "    test_time = time.time()\n",
    "    print(\"Test time for \"+str(i)+\" components: \"+str(test_time-save_time))\n",
    "    \n",
    "    print(\"--- Accuracy for \"+str(i)+\" components: \" + str(metrics.accuracy_score(test_labels, y_pred_bin)))\n",
    "    end = time.time()\n",
    "    print(\"time for \"+str(i)+\" components: \"+str(end-start))\n",
    "    print(\"=============\")\n",
    "# save_all(svc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all(svc=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
